# -*- coding: utf-8 -*-
"""Домашнее_задание «Обучение сверточной сети на практике

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DEZr3SkXBI5ADKMLSRAjHNeYpDM1XAmo
"""

import numpy as np
import pandas as pd
import os
import zipfile
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import log_loss
from sklearn.model_selection import train_test_split

# Распаковка архивов
def unzip_data(filename):
    with zipfile.ZipFile(filename, 'r') as zip_ref:
        zip_ref.extractall()

unzip_data("train.zip")
unzip_data("test.zip")

train_dir = "train"
test_dir = "test"

# Создание датафрейма с именами файлов и метками для тренировочных данных
filenames = os.listdir(train_dir)
labels = ["cat" if "cat" in name else "dog" for name in filenames]
data = pd.DataFrame({"filename": filenames, "label": labels})

# Разделение данных на обучающую и валидационную выборки
train_df, val_df = train_test_split(data, test_size=0.2, random_state=42)

# Генератор аугментации для тренировки
datagen_train = ImageDataGenerator(
    rescale=1./255,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    brightness_range=(0.8, 1.2),
    shear_range=0.2,
    zoom_range=0.3,
    horizontal_flip=True
)

# Для валидации (и теста) используем только рескейлинг
datagen_val = ImageDataGenerator(rescale=1./255)

train_gen = datagen_train.flow_from_dataframe(
    train_df,
    train_dir,
    x_col="filename",
    y_col="label",
    target_size=(224, 224),
    class_mode="binary",
    batch_size=32,
    shuffle=True
)

val_gen = datagen_val.flow_from_dataframe(
    val_df,
    train_dir,
    x_col="filename",
    y_col="label",
    target_size=(224, 224),
    class_mode="binary",
    batch_size=32,
    shuffle=False
)

# Используем MobileNetV2 как базовую модель
base_model = keras.applications.MobileNetV2(
    input_shape=(224, 224, 3),
    include_top=False,
    weights="imagenet"
)
base_model.trainable = True
for layer in base_model.layers[:-30]:
    layer.trainable = False

# Создаем модель с добавлением Batch Normalization и Dropout
model = keras.Sequential([
    base_model,
    keras.layers.GlobalAveragePooling2D(),
    keras.layers.BatchNormalization(),
    keras.layers.Dense(256, activation="relu", kernel_regularizer=keras.regularizers.l2(0.01)),
    keras.layers.Dropout(0.5),
    keras.layers.Dense(1, activation="sigmoid", kernel_regularizer=keras.regularizers.l2(0.01))
])

# Вместо Focal Loss используем BinaryCrossentropy с label smoothing для стабилизации предсказаний
loss_fn = keras.losses.BinaryCrossentropy(label_smoothing=0.1)

# Определяем CosineDecay Scheduler для управления скоростью обучения
lr_schedule = keras.optimizers.schedules.CosineDecay(
    initial_learning_rate=0.001,
    decay_steps=10 * len(train_gen),  # 20 эпох ,,,,,, уменьшил до 10 эпох
    alpha=0.01
)

# Компиляция модели
model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),
    loss=loss_fn,
    metrics=["accuracy"]
)

# Callback: ранняя остановка, если метрика валидации не улучшается
callbacks = [
    keras.callbacks.EarlyStopping(monitor="val_loss", patience=7, restore_best_weights=True)
]

# Обучение модели
history = model.fit(
    train_gen,
    validation_data=val_gen,
    epochs=10, # уменьшил на 10
    callbacks=callbacks
)

# Функция для Test-Time Augmentation (TTA)
def tta_predict(model, generator, n_aug=10):
    predictions = []
    for i in range(n_aug):
        print(f"TTA Round: {i+1}")
        preds = model.predict(generator, verbose=0)
        predictions.append(preds)
    return np.mean(predictions, axis=0)

# Оценка модели на валидационной выборке с использованием TTA
y_true = val_gen.classes
y_pred_tta = tta_predict(model, val_gen, n_aug=10)
y_pred_tta = np.clip(y_pred_tta, 1e-7, 1 - 1e-7)  # Избегаем логарифма от 0
print("Log Loss with TTA:", log_loss(y_true, y_pred_tta))

# ---- Подготовка файла для Kaggle ----

# Создаем датафрейм для тестовых данных: список файлов из папки test
test_filenames = os.listdir(test_dir)
test_df = pd.DataFrame({"filename": test_filenames})

# Генератор для тестовых данных (только рескейлинг)
test_gen = datagen_val.flow_from_dataframe(
    test_df,
    test_dir,
    x_col="filename",
    y_col=None,
    target_size=(224, 224),
    class_mode=None,
    batch_size=32,
    shuffle=False
)

# Предсказания для тестовых данных
test_preds = model.predict(test_gen)
test_preds = np.clip(test_preds, 1e-7, 1 - 1e-7)

# Формируем DataFrame для отправки на Kaggle:
# Здесь в столбце "id" содержится имя файла без расширения
submission = pd.DataFrame({
    "id": test_df["filename"].apply(lambda x: os.path.splitext(x)[0]),
    "label": test_preds.flatten()
})

# Сохраняем файл submission.csv
submission.to_csv("submission.csv", index=False)
print("Submission file saved as submission.csv")